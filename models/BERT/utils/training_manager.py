import torch
from transformers import (
    Trainer,
    TrainingArguments
)
from sklearn.metrics import f1_score, precision_score, recall_score
import mlflow, mlflow.pytorch
from tracking.save_registry import SaveTracking


# GPU í™•ì¸ í•¨ìˆ˜
def check_device():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if torch.cuda.is_available():
        print(f"âœ… GPU Detected: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸ No GPU Detected. Using CPU instead.")
    return device


# í‰ê°€ ì§€í‘œ í•¨ìˆ˜
def compute_metrics(eval_pred):
    """
    ê²€ì¦ ì‹œ F1 Score, Precision, Recallì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    logits, labels = eval_pred
    preds = torch.argmax(torch.tensor(logits), dim=-1).numpy()
    labels = labels
    
    f1 = f1_score(labels, preds, average='macro')
    precision = precision_score(labels, preds, average='macro')
    recall = recall_score(labels, preds, average='macro')
    
    return {
        'f1': f1,
        'precision': precision,
        'recall': recall
    }


# TrainingManager í´ë˜ìŠ¤
class TrainingManager:
    def __init__(self, model, tokenizer, learning_rate, experiment, epochs=5):
        self.learning_rate = learning_rate
        self.model = model
        self.tokenizer = tokenizer
        self.device = check_device()
        self.model.to(self.device)
        self.epochs = epochs
        self.experiment = experiment
        
        # ì‹¤í—˜ ì„¸íŒ…
        mlflow.set_tracking_uri(SaveTracking().mlflow_url)
        mlflow.set_experiment(self.experiment)
        print(f"ì‹¤í—˜ ì„¤ì • ì™„ë£Œ ì‹¤í—˜ë²„ì „ëª… {self.experiment}")
    
    def train(self, train_dataset, valid_dataset, output_dir, train_batch_size, valid_batch_size):
        """
        ëª¨ë¸ í•™ìŠµ, ê²€ì¦ ë° ìµœì  ëª¨ë¸ ì €ì¥
        """
        training_args = TrainingArguments(
            output_dir=output_dir,             # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
            num_train_epochs=self.epochs,       # í•™ìŠµ Epoch ìˆ˜
            per_device_train_batch_size=train_batch_size,     # GPUë‹¹ í•™ìŠµ ë°°ì¹˜ í¬ê¸°
            per_device_eval_batch_size=valid_batch_size,      # GPUë‹¹ ê²€ì¦ ë°°ì¹˜ í¬ê¸°
            warmup_steps=100,                   # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ì„ ìœ„í•œ ì›œì—… ìŠ¤í…
            weight_decay=0.01,                  # ê°€ì¤‘ì¹˜ ê°ì†Œ
            logging_dir='./logs',               # ë¡œê·¸ ì €ì¥ ê²½ë¡œ
            logging_steps=10,                   # ë¡œê·¸ ì¶œë ¥ ê°„ê²©
            evaluation_strategy='steps',        # ë§¤ Epochë§ˆë‹¤ Validation ì‹¤í–‰
            eval_steps=500,
            save_strategy='steps',              # ë§¤ Epochë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            load_best_model_at_end=True,        # ìµœì ì˜ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
            metric_for_best_model='f1',         # ìµœì  ëª¨ë¸ ê¸°ì¤€
            fp16=True if torch.cuda.is_available() else False,  # Mixed Precision í™œì„±í™”
            report_to='none',                   # TensorBoard ë¹„í™œì„±í™”
            logging_first_step=True,             # ì²« ìŠ¤í…ë¶€í„° ë¡œê·¸ ì¶œë ¥
            max_grad_norm=1.0   
        )
        
        # Trainer ê°ì²´ ìƒì„±
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=valid_dataset,
            tokenizer=self.tokenizer,
            compute_metrics=compute_metrics
        )
        
        with mlflow.start_run():
            mlflow.log_param("learning_rate", self.learning_rate)
            mlflow.log_param("epochs", self.epochs)
            mlflow.log_param("train_batch_size", train_batch_size)
            mlflow.log_param("valid_batch_size", valid_batch_size)
            # í•™ìŠµ ì‹¤í–‰
            print("ğŸš€ Starting Training...")
            trainer.train()
        
            # ê²€ì¦ ì‹¤í–‰
            print("ğŸ“Š Running Validation...")
            eval_results = trainer.evaluate()
            print("âœ… Validation Results:")
            for key, value in eval_results.items():
                print(f"{key}: {value:.4f}")
                # ë¡œê¹… ê²°ê³¼ ìˆ˜ì§‘ 
                mlflow.log_metric(key, value)
        
            # ìµœì  ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì €ì¥
            print("ğŸ’¾ Saving Best Model and Tokenizer...")
            trainer.save_model(output_dir)
            self.tokenizer.save_pretrained(output_dir)
            print(f"âœ… Model and Tokenizer Saved at {output_dir}")
            
            mlflow.pytorch.log_model(self.model, artifact_path=f"{self.experiment}/model")
            mlflow.log_artifacts(output_dir, artifact_path=f"{self.experiment}/artifacts")
            
            print(f"ëª¨ë¸ ì €ì¥ì™„ë¡œ: {self.experiment}/model")
            print(f"ì•„í‹°íŒ©íŠ¸ ì €ì¥ì™„ë£Œ: {self.experiment}/artifacts")
            
        return eval_results
